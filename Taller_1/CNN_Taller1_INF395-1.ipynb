{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias de Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "#Import from keras_preprocessing not from keras.preprocessing\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "#import pandas as pd\n",
    "#import numpy as np\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargando la data desde el archivo csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=pd.read_csv(r\"data/train_labels.csv\")\n",
    "path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_ext(fn):\n",
    "    return fn+\".jpg\"\n",
    "\n",
    "traindf=pd.read_csv(path+'train_labels.csv',dtype=str)\n",
    "\n",
    "traindf[\"Id\"]=traindf[\"Id\"].apply(append_ext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos generadores de keras para trabajar con las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6909 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=path+\"train_images/\",\n",
    "x_col=\"Id\",\n",
    "y_col=\"Expected\",\n",
    "subset=\"training\",\n",
    "batch_size=32,\n",
    "seed=30,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2303 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=traindf,\n",
    "directory=path+\"train_images/\",\n",
    "x_col=\"Id\",\n",
    "y_col=\"Expected\",\n",
    "subset=\"validation\",\n",
    "batch_size=32,\n",
    "seed=30,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "target_size=(128,128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer modelo de CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(128,128,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files_df=pd.DataFrame()\n",
    "test_files_df['file']=os.listdir(path+'test_images')\n",
    "#print(\"Loaded test files list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1023 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=ImageDataGenerator(rescale=1./255.).flow_from_dataframe(\n",
    "                    dataframe=test_files_df,\n",
    "                    directory=path+\"test_images\",\n",
    "                    x_col=\"file\",\n",
    "                    y_col=None,\n",
    "                    has_ext=True,\n",
    "                    class_mode=None,\n",
    "                    batch_size=32,\n",
    "                    seed=30,\n",
    "                    shuffle=False,\n",
    "                    target_size=(128,128))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción de modelo 1 (Model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_generator(test_generator)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando en csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id':test_generator.filenames,\n",
    "    'Expected':y_pred })\n",
    "# Filename is id, remove extension .tif\n",
    "submission_df['Id'] = submission_df['Id'].apply(lambda x: x.split('.')[0])\n",
    "#print(f\"Submission dataframe created. Rows:{len(submission_df.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_generator.class_indices\n",
    "for key in train_generator.class_indices:\n",
    "    submission_df['Expected'] = submission_df['Expected'].replace(train_generator.class_indices[key],key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('6-submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "215/215 [==============================] - 139s 645ms/step - loss: 0.2336 - accuracy: 0.9138 - val_loss: 0.1648 - val_accuracy: 0.9260\n",
      "Epoch 2/5\n",
      "215/215 [==============================] - 128s 596ms/step - loss: 0.1659 - accuracy: 0.9351 - val_loss: 0.1719 - val_accuracy: 0.9350\n",
      "Epoch 3/5\n",
      "215/215 [==============================] - 140s 651ms/step - loss: 0.1357 - accuracy: 0.9463 - val_loss: 0.2044 - val_accuracy: 0.9409\n",
      "Epoch 4/5\n",
      "215/215 [==============================] - 146s 677ms/step - loss: 0.1096 - accuracy: 0.9573 - val_loss: 0.1387 - val_accuracy: 0.9487\n",
      "Epoch 5/5\n",
      "215/215 [==============================] - 138s 641ms/step - loss: 0.0834 - accuracy: 0.9680 - val_loss: 0.1074 - val_accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Configure the CNN (Convolutional Neural Network).\n",
    "classifier = Sequential()\n",
    "'''\n",
    "# Convolution - extracting appropriate features from the input image.\n",
    "# Non-Linearity (RELU) - replacing all negative pixel values in feature map by zero.\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(128, 128, 3),\n",
    "               activation='relu'))\n",
    "# Pooling: reduces dimensionality of the feature maps but keeps the most important information.\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# Adding a second convolutional layer and flattening in order to arrange 3D volumes into a 1D vector.\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Flatten())\n",
    "# Fully connected layers: ensures connections to all activations in the previous layer.\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=10, activation='softmax'))\n",
    "'''\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "classifier.add(MaxPooling2D((2, 2)))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D((2, 2)))\n",
    "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D((2, 2)))\n",
    "classifier.add(Flatten()) \n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "classifier.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the CNN and train the classifier..\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "history=classifier.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicción con segundo modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict_generator(test_generator)\n",
    "#y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1023, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardando resultados de predicción para segundo modelo (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission_df2 = pd.DataFrame({\n",
    "    'Id':test_generator.filenames,\n",
    "    'Expected':y_pred })\n",
    "# Filename is id, remove extension .tif\n",
    "submission_df2['Id'] = submission_df2['Id'].apply(lambda x: x.split('.')[0])\n",
    "#print(f\"Submission dataframe created. Rows:{len(submission_df.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in train_generator.class_indices:\n",
    "    submission_df2['Expected'] = submission_df2['Expected'].replace(train_generator.class_indices[key],key)\n",
    "    \n",
    "submission_df2.to_csv('5-submission.csv', index=False)\n",
    "submission_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tercer modelo CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model_2.add(MaxPooling2D((2, 2)))\n",
    "model_2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model_2.add(Flatten()) \n",
    "model_2.add(Dense(64, activation='relu'))\n",
    "model_2.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = model_2.predict_generator(test_generator)\n",
    "y_pred_2 = np.argmax(y_pred_2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission df\n",
    "submission_df3 = pd.DataFrame({\n",
    "    'Id':test_generator.filenames,\n",
    "    'Expected':y_pred_2 })\n",
    "# Filename is id, remove extension .tif\n",
    "submission_df3['Id'] = submission_df3['Id'].apply(lambda x: x.split('.')[0])\n",
    "#print(f\"Submission dataframe created. Rows:{len(submission_df.values)}\")\n",
    "\n",
    "for key in train_generator.class_indices:\n",
    "    submission_df3['Expected'] = submission_df3['Expected'].replace(train_generator.class_indices[key],key)\n",
    "    \n",
    "submission_df3.to_csv('7-submission.csv', index=False)\n",
    "submission_df3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
